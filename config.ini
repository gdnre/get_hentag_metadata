# 网站的请求头，自行前往浏览器按f12-网络-标头-请求标头里复制，chrome中需要逐条复制，不然格式可能不对
[headers]
Accept : text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7
Accept-Encoding : gzip, deflate, br
Accept-Language : zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-TW;q=0.6,ja;q=0.5
####要修改的项别忘了取消注释
#Cookie : 
Dnt : 1
Sec-Ch-Ua : "Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"
Sec-Ch-Ua-Mobile : ?0
Sec-Ch-Ua-Platform : "Windows"
Sec-Fetch-Dest : document
Sec-Fetch-Mode : navigate
Sec-Fetch-Site : none
Sec-Fetch-User : ?1
Upgrade-Insecure-Requests : 1
User-Agent : Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36

[str]
# ehviewer下载文件夹前缀匹配的正则表达式，在压缩文件夹时，匹配的字符串会被删去
#regex_ehviewer_filename_start = ^\d+- *
# 数据库文件的名字(路径)，默认是脚本所在文件夹的相对路径
#db_path = file_list.db
#search_url = https://hentag.com/public/api/vault-search
# 存放漫画数据的数据表名
#table_name = file_list

##################################################################################################################
#注意win文件路径用 '\' ,linux、macos用 '/'
# 从ehviewer下载下来的漫画所在的目录，漫画以图片格式存放在子文件夹中，如果没有固定存放的目录就别填
ehviewer_dir_path =
####必填，漫画库根目录，即漫画压缩包所在的文件夹，漫画压缩后要放到的文件夹，例：/home/ehviewer
library_root_path =Z:\@Media\_Manga\_Lanraragi\Content_MangaData\e\hentag
####必填，漫画整理后要放到的文件夹，必须和上面的文件夹在同一分区，否则没法创建硬链接，例：/home/Lanraragi/Content
sort_root_path =
##################################################################################################################

# 分类子文件夹的根，相对根文件夹创建，不要输绝对路径，接上例，比如输hentag，就是放到/home/Lanraragi/Content/hentag里
#sub_path_root = hentag
# 各个分类所放到的文件夹，相对上述分类文件夹的根
#sub_path_artist = artist
#sub_path_group = group
#sub_path_unsorted = unsorted

[int]
# 向hentag服务器搜索成功后等待的时间，防止请求太频繁
wait_time = 1
# 模式1的搜索超时时间，1、2、3分别对应第几次，每次都将搜索所有未请求数据，比如列表中有10条数据，会将10条都搜一遍，再重复下一次
timeout1 = 5
timeout2 = 10
timeout3 = 15
# 模式2最大尝试次数，假如设置为5，列表中有10条数据，会先搜索第一条数据，成功或者失败5遍，再搜索下一条
max_retry_count = 3

[json]
# 模式2每次搜索的超时时间列表，每个元素的含义是[下n次,每次增加的时间]，比如[1,10]就代表下1次请求增加10s；
# 组合起来，[[1, 10], [2, 5]]就代表[10,15,20]，之后的次数都会使用设置的最后一个超时时间
# 别作死往第一个数组里填0，或者增加时间填负数
timeout_rule=[[1, 7], [2, 5]]

